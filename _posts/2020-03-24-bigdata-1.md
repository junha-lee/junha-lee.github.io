---
title: "Understading BigData(1)"
categories: 
  - BigData
last_modified_at: 2020-03-25T00:48:00+09:00
toc: true
---

Intro
---
학교 수강과목에서 학습한 내용을 복습하는 용도의 포스트입니다.<br/>
빅데이터 개념과 오픈소스인 아파치 하둡과 맵리듀스 및 스파크를 이용한 빅데이터 적용을 공부합니다.<br/>
맵 리듀스의 경우 사용하기에 다소 진입장벽이 있는편입니다.<br/> 스파크처럼 통합 환경을 제공하지 않아 원하는 유틸리티나 라이브러리를 별도로 연결해서 사용해야하기 때문입니다. 이를 해소하는 것이 스파크라는 분산 데이터 처리 통합 엔진입니다.<br/>
따라서 맵 리듀스로 먼저 공부해보고, 스파크로 넘어갑니다.<br/>

스파크 엔진의 경우 Java가 아닌 Scalar라는 언어로 사용하며, 기존 우리가 알고 있는 SQL을 통해 고급 질의가 가능하며, 시각화나 스트림 처리 및 기계학습등 까지의 높은 수준의 분석을 제공하는 통합 프레임 워크입니다.<br/>

빅데이터 컴퓨팅(분산시스템상의 분산처리 환경)의 기본 개념과 원리를 이해하고 이를 실습해보는 과정에서 2대 이상의 리눅스 클러스터 서버를 구축 및 활용할 것입니다.<br/>

이번 주제는 빅데이터 컴퓨팅의 소개입니다.<br/>

빅데이터 정의
---

기존의 단일 컴퓨터 방식으로 표현/저장/처리/분석하기 어려운 큰 규모의 자료<br/>

\<기존 방식으로 처리가 불가한 이유><br/>
* 기존의 방식대로면 DB에 데이터를 저장합니다. 그러기 위해서는 구조화된 데이터여야합니다. schema 구성에 맞게 레코드를 구성하기 때문이지요.<br/>
* 반면 빅데이터의 경우는 일반적으로 구조화되지 않았거나(ex)이미지데이터, 텍스트데이터, 오디오데이터 등) 반구조화된 데이터(ex)xml, json 등)의 혼합입니다.<br/>
* 대규모입니다. 그래서 저장하는 것부터 어려움을 겪을 수 있으며 처리나 분석까지는 더욱이 어렵지요.<br/>

따라서 빅데이터만을 위한 환경이 필요합니다.<br/>

**빅데이터소스**로는 매일 발생하는 정보소비자로부터의 데이터(sns, 웹로그, 의료기록 등), 기상정보, 유전정보, 센서데이터, 카메라데이터, RFID 등 여러가지가 있습니다.<br/>

\<빅데이터 특성, 3V><br/>
* 규모(Volume) : 대규모입니다. 단일 처리가 불가합니다.
* 다양성(Variety) : 구조화된 데이터도 안된 데이터도, 반만된 데이터도 있습니다.
* 속도(Velocity) : 실시간으로 생성되는 데이터를 처리 또는 분석할 수 있어야합니다.

\<빅데이터 3V에 대처한 혁신적인 사례><br/>
* 웹 검색엔진으로 유명한 Google입니다. 3V 관점에서 설명해보겠습니다.<br/>
* Volume : 대규모 데이터 목록에 색인을 만들어 키워드가 들어오면 색인을 통해 웹페이지를 찾아줄 수 있어야 합니다.<br/>
* Variety : 다양하게 표현된 웹페이지를 읽어들일 수 있어야합니다. 하나의 웹 문서 안에도 여러 DOM이 존재하기 때문이지요.<br/>
* Velocity : 대부분의 웹페이지는 계속해서 변화합니다. 이에 빠른 속도로 수집하고 처리할 수 있어야합니다.<br/>
* 이 세 특징을 모두 고려해 개발해야했지요.<br/>

어떻게 해결했는지는 바로 이어서 설명하겠습니다.<br/>
<br/>

빅데이터 컴퓨팅 주요 개념
---

\<구글의 해결방안><br/>
상호 연결된 다수의 저가형 범용 컴퓨터를 각각의 노드로 하여 노드들의 집합, 즉 클러스터를 구성합니다.<br/>
이렇게 구성된 노드들에는 고장 감내(tolerance)를 위해 원본 데이터의 복사본이 여럿 분산되어 저장되게 됩니다.<br/>
고장나더라도 쉽게 교체가 가능하기 때문이지요.<br/>

여러 컴퓨터에 하나의 대규모 데이터를 병렬처리하는데에 요구되는 분산파일시스템으로 **GFS**를 개발하였습니다.<br/>

또한 비구조화 데이터를 저장하기 위해 기존의 SQL 아닌 NoSQL(=Wide Column Store)로 처리하려고 GFS상의 데이터베이스시스템인 **빅테이블**을 만들었습니다.<br/>

빅테이블과 기존 DB와의 차이점은 첫 번째, 여러 노드에 분산되어 저장이 가능하다. 두 번째, 추가만 가능하며 수정이 불가(immutable)하다.입니다.<br/>
왜 수정이 불가하게 만들었을까요?<br/>
수정으로 인한 동기화 문제를 없앰으로써 병렬처리 문제를 완화하기 위해서 입니다.<br/>

구글에서는 빅테이블을 *a sparse, distributed persistant multi-dimensional sorted map*이라고 소개합니다.<br/>
빅테이블에서 데이터를 사상하기 위한 방법으로는 (행키, 열기, 타임스탬프)로 구성된 셀(cell)을 이용합니다.<br/>
행키와 열키는 기존 DB에서 사용하니 익숙하실테지만, 타임스탬프라는 것이 생소하실 겁니다.<br/>
바로 이 시간정보에 대한 키가 있기 때문에 기존 데이터를 덮어쓸 필요가 없는 것입니다.<br/>
또 수정하지 않으니 기존 파일을 재구성 할 필요 없이 추가만을 계속해서 하다가 꽉차면 노드만을 새롭게 추가하면 되는 것이지요.<br/>그래서 확장성이 매우 높다는 특징을 갖습니다.<br/>

여러 노드에 분산해서 저장하기 위해 빅테이블에서는 부분테이블인 **태블릿**으로 분할하여 로드 밸런싱을 제공합니다.<br/>

그리고 이와 같은 환경에서 실질적으로 병렬처리를 하기 위한 기법으로 **Map Reduce**를 사용였습니다.<br/>

참고로 Map Reduce는 본래 LISP이라는 함수형언어에서 리스트 데이터를 처리할 때 사용하는 Map()이라는 함수와 Reduce()라는 함수에 근간을 두고 있습니다.<br/>

리스트의 각 원소가 하나의 노드 또는 데이터 컬렉션이 되며 map()은 동시 병렬처리를 위한 용도로, reduce()는 여러 컴퓨터에서 하나의 결과를 산출하기 위한 용도로 사용됩니다.<br/>

구글은 이렇게 개발한 혁신적인 빅데이터 환경을 논문으로 투고하였고, 야후에서 이를 참고해 오픈소스로 개발한 또 다른 빅데이터를 위한 분산파일시스템이 바로 **아파치 하둡**입니다.<br/>
구글에서의 DB는 빅테이블이라면 하둡에서는 HBase이며, 구글에서의 분산파일시스템이 GFS라면 하둡에서는 HDFS입니다.<br/>
그리고 양쪽 모두 병렬처리기법으로는 맵리듀스를 채용하였죠.<br/>
<br/>

빅데이터 파이프라인
---

빅데이터의 처리 및 분석 단계에 대한 설명을 위해 데이터 파이프라인 개념을 소개합니다.<br/>
우리는 데이터 소스로부터 수집(Ingestion)하여 처리(Processing)를 하고 그 결과를 분석(Analysis)하곤 합니다.<br/>

수집, 처리, 분석이 분산 파일시스템 상에서 이루어져 순환을 하기도 하는데 이것이 바로 데이터 파이프라인입니다.<br/>

우리는 데이터 파이프라인을 시작하기 전에 3V 관점에서 프로젝트를 정의할 수 있어야합니다.<br/>
* Volume : 고장감내 목적의 복제에 필요한 용량, 운영체제 용량, 메타데이터 용량 등을 모두 고려하면 실제 데이터의 용량의 총 4배정도의 공간을 필요로 합니다.<br/>
* Variety : 간단히 콤마(,)로 구분되는 csv나 xsl파일부터, HBase 데이터, 열중심저장의 Parquet 데이터, 객체 표현형식인 반구조화 데이터인 JSON까지 다양한 모습의 데이터가 존재합니다.<br/>
* Velocity : 과거 추이 분석 목적의 특정 서버로 부터 다운로드받는 Batch Data의 경우에는 따로 분석을 즉시할 필요가 없을 수 있으나, IoT sensor data의 경우 Streaming Data로서 실시간에 준하는 분석을 필요로 하니 이런 점도 고려해주어야합니다.<br/>

이를 고려하여 데이터를 선정하고 수집(ingestion)하였다면 데이터를 HBase등에서 추출(Extract)해와 용도에 맞게 적절히 변환(transform)하여 메모리로 적재(Load)하는 일련의 과정을 거치게 됩니다. 이 과정이 바로 **데이터 처리 ETL(Extract, Transform,Load)**입니다. 참고로 transform 과정에서는 Normalization, Cleaning, Sampling, Splitting 등의 작업을 모두 포함합니다.<br/>

이후 분석(Analysis) 단계에서는 앞서 처리단계(Processing)에서 적재된 데이터를 가지고 데이터 시각화를 한다던지, 의사결정을 한다던지, 심층신경망에 입력데이터로 사용한다던지 하는 것 입니다!<br/>

다음 시간에는 이러한 파이프라인 과정을 Apache Hadoop 이라는 분산파일시스템과 맵리듀스라는 병렬처리기법으로 적용해보는 시간을 갖을 예정입니다.<br/>
<br/>
<br/>
개인이 공부하고 포스팅하는 블로그입니다. 작성한 글 중 오류나 틀린 부분이 있을 경우 과감한 지적 환영합니다!<br/><br/>