---
layout: post
title: CNN 개요
date: 2020-07-10 00:30:00
category: coal
tags:
    - deep learning
    - image detection
    - coal
    - IoT
mathjax: true
comment: true
---

## 역사

* 1989년 LeCun이 발표한 논문 “Backpropagation applied to handwritten zip code recognition”에서 처음 소개, 범용화에는 미흡
 
* 이후 2003년 Behnke의 논문 “Hierarchical Neural Networks for Image Interpretation”을 통해 일반화

* Simard의 논문 “Best Practices for Convolutional Neural Networks Applied to Visual Document Analysis”을 통해 단순화  

* 이후 GP-GPU (General Purpose GPU)를 통해 CNN을 구현할 수 있는 방법이 소개 되었고, 활성화


# 왜 CNN 인가? 

* 기존 완전 연결 계층의 문제점

데이터 형상 무시

- 공간적 정보 무시
- 학습 시간 증가
- 많은 학습 데이터 필요

-> 데이터의 형상을 반영할 수 있는 학습 방법이 필요

CNN을 통해 이미지를 벡터 형식으로 변환하지 않고, 픽셀 간의 관계를 특징으로 인식 할 수 있게 되었다.


# CNN 특징


- 1980년대부터 이미지 인식 분야에 사용
- 컴퓨터 성능의 향상
- 많은 양의 훈련 데이터
- 심층 신경망 훈련
- 이미지 처리 및 음성 처리 분야에 주로 사용

# CNN 구조

![](https://raw.githubusercontent.com/junha-lee/junha-lee.github.io/main/assets/images/cnn.png)

* 합성곱 층 – 합성곱 연산(필터 연산)을 처리하는 계층으로 첫 은닉층은 저수준 특성에 집중하고, 다음으로 갈 수록 고수준 특성으로 조합해 나감.

* 패딩 – 합성곱 연산을 반복하기 위해 출력의 크기가 같아야 한다. 이에 출력 크기를 조정하기 위해 입력 데이터 주위에 0을 채워 출력 크기 조정하는 것을 의미함.

* 스트라이드 – 필터가 이동하는 간격을 의미, 출력 크기를 조절하기 위해 사용


* 풀링 층 – 해당 영역의 최대 or 평균 값을 대표값으로 하여 데이터 크기 줄이는 것 -> 모델의 전체 매개변수의 수 감소, 불변성을 찾아내서 공간적 변화를 극복

* 층이 깊어지면서 뉴런이 반응하는 대상이 단순한 모양에서 정보로 변화해 간다. -> 사물의 의미를 이해하도록 변한다.


# 하이퍼파라미터 최적화

* 층 수
* 층마다 뉴런 수
* 각 층에서 사용하는 활성화 함수
* 가중치 초기화 방식

###  어떤 조합이 문제 해결에 가장 좋은지 판단하는 방법

1. 많은 조합을 시도하고 검증셋 (또는 K-폴드 교차 검증) 성능 확인

2. 좋은 하이퍼파라미터 조합을 빠르게 찾아주는 기법 활용

- 특정 하이퍼파라미터 공간에서 좋은 결과가 나오면 근처를 더 찾기

- 하이퍼파라미터 최적화 기법을 구현한 파이썬 라이브러리 사용
* Hyperopt, Hyperas, Scikit-Optimize, Spearmint, Sklearn-Deap 등

- 마지막 방법은 하이퍼파라미터 최적화 서비스를 제공하는 회사 제품 이용
− Google Cloud ML Engine, Arimo, SigOpt, Oscar 등


### 마치며

앞으로의 연구에 쓰일 CNN에 대해 간단하게 정리 해 봤습니다.

읽어주셔서 감사합니다.


```python

```
