---
title: "Intro of Hadoop-Understading BigData(5)"
categories: 
  - BigData
last_modified_at: 2020-04-25T20:51:00+09:00
toc: true
---

Intro
---
학교 수강과목에서 학습한 내용을 복습하는 용도의 포스트입니다.<br/>
빅데이터 개념과 오픈소스인 아파치 하둡과 맵리듀스 및 스파크를 이용한 빅데이터 적용을 공부합니다.<br/>
맵 리듀스의 경우 사용하기에 다소 진입장벽이 있는편입니다.<br/> 스파크처럼 통합 환경을 제공하지 않아 원하는 유틸리티나 라이브러리를 별도로 연결해서 사용해야하기 때문입니다. 이를 해소하는 것이 스파크라는 분산 데이터 처리 통합 엔진입니다.<br/>
따라서 맵 리듀스로 먼저 공부해보고, 스파크로 넘어갑니다.<br/>

스파크 엔진의 경우 Java가 아닌 Scalar라는 언어로 사용하며, 기존 우리가 알고 있는 SQL을 통해 고급 질의가 가능하며, 시각화나 스트림 처리 및 기계학습등 까지의 높은 수준의 분석을 제공하는 통합 프레임 워크입니다.<br/>

빅데이터 컴퓨팅(분산시스템상의 분산처리 환경)의 기본 개념과 원리를 이해하고 이를 실습해보는 과정에서 2대 이상의 리눅스 클러스터 서버를 구축 및 활용할 것입니다.<br/>

[빅데이터이해(1) 보러가기](https://ohjinjin.github.io/bigdata/bigdata-1/)<br/>
[빅데이터이해(2) 보러가기](https://ohjinjin.github.io/bigdata/bigdata-2/)<br/>
[빅데이터이해(3) 보러가기](https://ohjinjin.github.io/bigdata/bigdata-3/)<br/>
[빅데이터이해(4) 보러가기](https://ohjinjin.github.io/bigdata/bigdata-4/)<br/>

이번 시간엔 하둡 클러스트 개요에 대해 공부합니다.<br/>

하둡 클러스터 개요
---
개요를 배우기 전에 용어 정리를 하고 들어가겠습니다.<br/>

1. 클러스터(Cluster)
독립된 컴퓨터들의 네트워크를 말합니다.<br/>
각 컴퓨터는 자신만의 독자적인 메모리와 운영체제를 가집니다.<br/>
각 클러스터들은 입출력 연결망(interconnection)으로 연결되어 협업 작업을 합니다.<br/>
예를 들어 ethernet으로 연결해서 MAC 주소로 통신을 하거나 (switch계층), internet으로 연결해서 IP 주소로 통신을 할 수 있습니다.<br/>
클러스터를 이해하기 위해서는 컴퓨터 구조 과목 관점에서 이해해야합니다.<br/>

2. 분산시스템(Distributed System)
그에 반해 분산시스템은 클러스터 상에서 동작하는 하나의 시스템인데, file system일 수도 있고 OS일 수도 있고 특수 목적의 어플리케이션일 수도 있습니다.<br/>
대용량 데이터를 처리하거나 관리하기 위해 여러개의 (네트워크로 연결된)컴퓨터(=클러스터) 상에서 하나의 시스템처럼 사용할 수 있도록 구성한 시스템을 말합니다.<br/>
분산시스템을 이해하기 위해서는 운영체제 과목 관점에서 이해해야합니다.<br/>

그래서 하둡은 여러 클러스터 상에서 분산된 파일시스템(Hadoop Distribued File System)과 분산처리시스템(Map Reduce) 두 개의 중요한 구성요소를 가지고 동작하는 시스템입니다.<br/>

하둡 주요 구성 요소
---
HDFS 분산파일시스템과 맵리듀스라는 분산처리 시스템으로 구성됩니다.
하나의 마스터노드와 여러 슬레이브노드 구조로 구성됩니다.<br/>
HDFS에서 마스터는 name node라는 이름으로 불리며 슬레이브는 data node라고 불립니다.<br/>
맵리듀스에서 마스터는 JobTracker라고 하며 슬레이브 노드는 TaskTracker라고 부릅니다.<br/>
맵리듀스에서는 JobTracker의 관리 하에 각 TaskTracker들이 요구된 작업에 대해 병렬로 수행되는 것입니다.<br/>

HDFS는 하나의 파일시스템이기 때문에 마스터인 name node가 파일의 meta 정보를 관리하고, 실제 데이터는 여러 대의 data node에 분산해서 저장하게 됩니다.<br/>
이 때 분산 크기는 64MB라는 디폴트 블록단위로 나뉘어 관리하게 됩니다.<br/>

또 하나의 중요한 특징은 클러스터의 여러개의 노드에서 하나의 노드가 죽더라도 고장감내를 위해 그 64MB의 데이터는 여러 대의 데이터 노드에 분산 및 복제해서 저장되게 됩니다.<br/>

{% raw %} <img src="https://ohjinjin.github.io/assets/images/20200418bigdata/capture49.JPG" alt=""> {% endraw %}

위 그림은 하나의 Hadoop System Architecture로 저런게 여러대 있다고 이해하시면 됩니다.<br/>
또한 Job tracker와 Name node가 서로 분리되어있지만 하나의 노드 안에 있을 수도 있습니다.<br/>

분산시스템은 여러개의 클러스터의 노드 상에서 동작하기 때문에 마스터 노드는 슬레이브 노드가 죽었는지 살았는지 확인하기 위해 주기적으로 신호를 보내는데 그 신호를 Heart Beat라고 말합니다.<br/>

{% raw %} <img src="https://ohjinjin.github.io/assets/images/20200418bigdata/capture50.JPG" alt=""> {% endraw %}


그래서 분산 파일시스템과 분산 처리 시스템이 동작할 때 masternode와 name node는 별개로 동작합니다.<br/>

클라이언트는 master node에 바로 원격으로 요청할 수도 있고, 특정 slave node에 개별적으로 요청할 수도 있습니다.<br/>

클라이언트가 master node에게 어떤 요청을 했을 때 master node는 각 task tracker에게 작업을 할당하며 병렬로 처리하게 됩니다.<br/>
그렇게 병렬 처리된 결과를 함축하여 응답하게 되겠지요.<br/>

하둡 분산 파일 시스템은 그저 분산해서 저장되는 것만 빼고는 하나의 파일 시스템일 뿐입니다.<br/>
대규모 데이터를 높은 가용성을 유지하며 관리하기 위한 목적으로 설계되었을 뿐이랍니다.<br/>
파일 혹은 디렉토리의 복사, 이동, 삭제 및 권한 설정 등의 기능을 제공하며 익숙한 트리 형식의 디렉토리 구조로 관리하고 있기 때문에 기존의 일반 파일 시스템과 유사합니다.<br/>

일반 파일 시스템과 같이 사용은 되지만, 분산 파일 시스템이기 때문에 발생하는 **차이점**에 대해 다시 정리해보겠습니다.<br/>

1. 데이터 블록(Data Block)
HDFS는 파일을 블록단위로 분할하고 여러 데이터 노드에 분산 저장합니다.<br/>
각 파일의 기본 정보(이름, 디렉토리, 권한 etc) 및 각 블록들의 위치 정보를 name node에서 관리합니다.<br/>
파일을 블록 단위로 분할하여 관리하므로 하나의 파일이 수 테라 바이트 정도로 크더라도 관리가 가능합니다.<br/>
참고로 보통 하나의 블록은 수십 ~ 수백 메가 바이트 정도로 설정합니다.<br/>

2. 복제(Replication)
일부 데이터 노드에 장애가 발생할 경우 데이터의 손실을 막기 위해 각 데이터 블록에 대해서 여러 개의 복제본(Replica)을 가집니다.<br/>
복제본의 개수는 파일별로 직접 사용자가 지정해 줄 수 있으며 직접 지정하지 않으면 보통 **3개의 복제본**을 유지합니다.<br/>
name node는 data node들과 주기적으로 통신하면서 데이터 노드의 상태를 감시합니다.<br/>
이렇게 상태 확인을 위해 주고 받는 패킷을 **Heart Beat**라고 합니다.<br/>

3. 랙 인지(Rack Awareness)
클러스터의 구조는 랙이라는 케이스에 여러 개의 노드를 그룹화합니다.<br/>
한 클러스터에는 여러 개의 랙이 있으며, 한 랙에는 여러 개의 노드가 있습니다.<br/>
그래서 어떤 데이터가, 어떤 노드가 어디 랙에 있는가와 관련된 위상 구조(Topology)를 관리 해줘야합니다.<br/>
또한 topology를 토대로 복제본이 한 군데에 몰려 있지 않도록 해줘야하는데, 예를 들어 복제본 개수가 3인 경우 두 개는 같은 랙의 다른 노드에 저장하고 나머지 하나는 다른 랙에 있는 노드에 저장해줘야합니다.<br/>

4. 데이터 읽기 : 지역성(Locality)
분산 시스템에서 가장 부하가 많이 걸리고 성능에 영향을 많이 미치는 것은 바로 노드들 간의 통신입니다.<br/>
먼저 데이터를 읽기 위해서는 가장 가까운 데이터 노드에서 블록 정보를 가져올 수 있어야 합니다.<br/>
네임 노드에 해당 파일 위치 정보를 요청하고 읽기 요청을 한 노드와 가장 가까운 데이터 노드 순으로 정렬해서 알려주게 되어 부하를 최소화합니다.<br/>

5. 데이터 쓰기 : 일관성(Consistency)
같은 블록이 여러개의 데이터 노드에 복제되어 저장되었기 때문에 한쪽에 수정되더라도 나머지 흩어진 복사본들도 모두 같이 수정내역이 반영되어야겠지요?<br/>
사용자 또는 프로세스가 name node에게 파일쓰기를 요청합니다.<br/>그럼 name node는 해당 파일이 이미 있는지, 사용자가 쓰기 권한을 갖고 있는지 등 기본적인 유효성 검사를 수행합니다.<br/>
이 검사가 완료되면 네임 노드는 데이터를 저장할 데이터 노드 리스트를 사용자에게 전달합니다.<br/>
사용자는 이 중에서 첫번째 데이터 노드에 데이터 쓰기를 시작하고 이 데이터 노드는 다른 데이터 노드들과 파이프 라인처럼 연결되어 순차적으로 복제 데이터의 쓰기를 수행하게됩니다.<br/>
그렇기 때문에 첫번째 데이터 노드에 쓰기 작업이 완료되더라도 모든 복제본 생성이 완료될때까지 대기해야합니다.<br/>

이상으로 하둡 클러스터에서의 분산파일시스템인 HDFS에 대한 소개를 마쳤습니다.<br/>
master node인 Job Tracker와 slave node인 Task Tracker 소개는 다음 시간에 알아보도록 합시다!<br/>
다음 시간엔 job tracker가 작업을 요청받아 job 객체를 생성해 task에 분산 및 분배하여 병렬 수행하는 Map-Reduce 동작을 다뤄보게 될 것입니다.<br/>

<br/>
개인이 공부하고 포스팅하는 블로그입니다. 작성한 글 중 오류나 틀린 부분이 있을 경우 과감한 지적 환영합니다!<br/><br/>